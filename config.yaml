# Debug set to true in order to debug high-layer code.
# CFG Configuration
CFG:
  DEBUG: false
  num_workers: 2
  train_batch_size: 256
  valid_batch_size: 128

  # Train configuration
  TRAIN_TOKENIZER: false
  PREPROCESS: false
  user_name: "snoop2head"
  num_epochs: 10 # validation loss is increasing after 5 epochs
  max_token_length: 64
  stopwords: []
  learning_rate: 0.0005 # has to be set as float explicitly due to https://stackoverflow.com/questions/30458977/yaml-loads-5e-6-as-string-and-not-a-number
  weight_decay: 0.01 # https://paperswithcode.com/method/weight-decay
  adam_beta_1: 0.9
  adam_beta_2: 0.98
  epsilon: 0.000000001

  # Translation settings
  src_vocab_size: 10000
  tgt_vocab_size: 10000
  src_language: "ko"
  tgt_language: "en"
  load_model_name: "snoop2head/Deep-Shallow-Ko2En"
  num_inference_sample: 5000

  # transformer settings
  emb_size: 512
  attention_heads: 8
  ffn_hid_dim: 2048
  encoder_layers: 12
  decoder_layers: 1
  is_encoder_decoder: true
  activation_function: "gelu"
  dropout: 0.1

  # root path
  ROOT_PATH: "."
